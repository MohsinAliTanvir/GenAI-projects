{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PA2.1 - Building your first Chatbot: Aleeza\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this notebook, you will be implementing your own version of the first ever Chatbot, ELIZA.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- Follow along with the notebook, filling out the necessary code where instructed.\n",
    "\n",
    "- <span style=\"color: red;\">Read the Submission Instructions and Plagiarism Policy in the attached PDF.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Make sure to run all cells for credit.</span>\n",
    "\n",
    "- <span style=\"color: red;\">Do not remove any pre-written code.</span> We will be using the `print` statements to grade your assignment.\n",
    "\n",
    "- <span style=\"color: red;\">You must attempt all parts.</span> Do not assume that because something is for 0 marks, you can leave it - it will definitely be used in later parts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background: ELIZA\n",
    "#### The first ever Chatbot.\n",
    "\n",
    "<div style=\"display: flex; justify-content: center;\">\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/79/ELIZA_conversation.png\" width=\"400\" height=\"250\" alt=\"ELIZA Conversation\">\n",
    "</div>\n",
    "\n",
    "This Chatbot was released in 1966 (before the term Chatbot even existed) by Joseph Weizenbaum of MIT. This was a revolutionary program that allowed humans to converse with a computer. As you may have predicted, this was a retrieval-based system, very different from the \"language models\" of today. However, you may be surprised by how well it performed despite the simplicity of the system. Here is part of a conversation someone had with ELIZA, from the original paper (the capitalised sentences are ELIZA's responses):\n",
    "\\\n",
    "\\\n",
    "Men are all alike.\\\n",
    "IN WHAT WAY\\\n",
    "They're always bugging us about something or other.\\\n",
    "CAN YOU THINK OF A SPECIFIC EXAMPLE\\\n",
    "Well, my boyfriend made me come here.\\\n",
    "YOUR BOYFRIEND MADE YOU COME HERE\\\n",
    "He says i'm depressed much of the time.\\\n",
    "I AM SORRY TO HEAR YOU ARE DEPRESSED\\\n",
    "It's true. I am unhappy.\\\n",
    "DO YOU THINK COMING HERE WILL HELP YOU NOT TO BE UNHAPPY\\\n",
    "......\n",
    "\n",
    "The program used certain programmed rules to \"transform\" the input into the output. In order to do this, the program must first decompose the sentence based on certain criteria and then reassemble it based on the predefined assembly specifications. For example, if it is provided with the input sentence, \"It seems that you hate me\", it may be decomposed into:\n",
    "\n",
    "1) It seems that\n",
    "2) you\n",
    "3) hate\n",
    "4) me\n",
    "\n",
    "Of these, (2) and (4) are recognised as key words. The program can then use the remaining sections of the sentence based on pre-defined rules to construct an output. For example, it may be programmed with the rule:\n",
    "\n",
    "decomposition template:\\\n",
    "(0 YOU 0 ME)\\\n",
    "and the reassembly rule:\\\n",
    "(WHAT MAKES YOU THINK I 3 YOU).\n",
    "\n",
    "Here, the \"0\" represents any number of words, whereas the \"3\" represents the 3rd part of the sentence from before. Hopefully, this makes the implementation a little clearer. If not, don't worry as you'll understand how it works once you start implementing your own version!\n",
    "\n",
    "For more details on the original ELIZA implementation, [Click Here](https://web.stanford.edu/class/cs124/p36-weizenabaum.pdf).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifications\n",
    "\n",
    "As described above, your task will be to first read in a user string, then modify it to provide an output (sometimes subtly, sometimes drastically, depending on the input string). This should be easy to do with the regex library, the specifics of which were discussed in class.\n",
    "\n",
    "\\\n",
    "Your program should be able to handle all 1st and 2nd person pronouns, all 1st and 2nd person subject-verb pairs with the verb be and all possible forms of the verb. If it is unclear what is meant by this, you might want to do some googling.\n",
    "\n",
    "\\\n",
    "An example is as follows:\n",
    "\n",
    "Regular Expression: I am (.*)\\\n",
    "Response: How long have you been %1?\n",
    "\n",
    "Example Input that matches: I am sad.\\\n",
    "Example Response: How long have you been sad?\n",
    "\n",
    "Please note that this is a simplified version of the chatbot, and the original bot had a much more complex algorithm behind it.\n",
    "\n",
    "You will have two tables to store all the logic of your bot:\n",
    "1. Reflection Table\n",
    "2. Response Table\n",
    "\n",
    "These will be described in detail in the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the ONLY imports you can use for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tables\n",
    "\n",
    "These are your reflection and response tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection Table\n",
    "\n",
    "This table serves to convert your pronouns from first person to second person and vice versa. You should list all forms of the pronouns and their corresponding \"reflection\". (eg. i : you)\\\n",
    "\\\n",
    "You should also do the same for all the forms of the verb \"be\". (eg. am : are)\\\n",
    "\\\n",
    "Note: You do not need to add plural pronouns such as \"we\".\\\n",
    "\\\n",
    "This table will be represented as a dictionary. (The first entry is listed as an example below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "reflectionTable = {\n",
    "    \"i\"    : \"you\",\n",
    "    \"me\": \"you\",\n",
    "    \"my\": \"your\",\n",
    "    \"am\": \"are\",\n",
    "    # Add entries here\n",
    "\n",
    "    #forms of verb be\n",
    "    \"is\": \"are\",\n",
    "    \"was\": \"were\",\n",
    "    \"were\": \"was\",\n",
    "    \"being\": \"being\",\n",
    "    \"been\": \"been\",\n",
    "    \"be\": \"be\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Response Table\n",
    "\n",
    "This table is in the form of a nested list. Each entry is a list, with the first term being your regular expression and the second term being a list of possible responses. \"%n\" represents the nth match. You will need to handle this in your code later when replacing the relevant parts of the text.\n",
    "\n",
    "Since this is a fairly large table, you will fill out the regular expressions and the responses in a json file: \"responseTable.json\"\n",
    "\n",
    "\\\n",
    "In this table, you must include ALL subject-verb pairs for the verb \"be\". Do this for first, second and third person pronouns. (eg. I am ...) You must add at least 3 appropriate responses for each of these pairs. You need not account for the contracted versions of the pairs. But, DO include the corresponding question statements for each of these pairs. You can assume there will be no past-tense or future-tense inputs.\\\n",
    "\\\n",
    "Furthermore, in the case that you encounter no matches, you must have fallbacks. Due to this, you must also account for the following cases:\n",
    "1. (I feel ...), (I want ...), (I think ...)\n",
    "2. Subject with an unknown verb\n",
    "3. An unrecognised question\n",
    "4. Any string\n",
    "\n",
    "Include 4 or more responses for these cases as they will likely be encountered more often.\\\n",
    "\\\n",
    "Lastly, add at least 3 more subject-verb pairs, with at least 1 response each. These can be anything you like. Have fun with it (but keep it appropriate).\\\n",
    "\\\n",
    "For example:\n",
    "\n",
    "Regex: I voted for (.*)\n",
    "\n",
    "Response: How did voting for (.*) make you feel?\n",
    "\n",
    "Please ensure the correct order, as you will only be checking the first match later on.\\\n",
    "Once again, an example entry has been provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add entries in the JSON file\n",
    "\n",
    "responseTable = json.load(open('responseTable.json'))\n",
    "#print(responseTable[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions (Optional)\n",
    "\n",
    "If you wish to modularise your code to make your life simpler in the upcoming cells. Please define your helper functions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aleeza Class\n",
    "\n",
    "This is the class you will be implementing all of your bot's functionality in. As you will see, this is very straightforward and most of the actual work will be done while writing the response table. We will call our version Aleeza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aleeza:\n",
    "  def __init__(self, reflectionTable, responseTable):\n",
    "    \"\"\"\n",
    "    Initiliase your bot by storing both the tables as instance variables.\n",
    "    You can store them any way you want. (Dictionary, List, etc.)\n",
    "    \"\"\"\n",
    "    self.__reflectionTable=reflectionTable #This is a dictionary\n",
    "    self.__responseTable=responseTable\n",
    "\n",
    "    # Code here\n",
    "\n",
    "  def reflect(self, text):\n",
    "    \"\"\"\n",
    "    Take a string and \"reflect\" based on the reflectionTable.\n",
    "\n",
    "    Return the modified string.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Code here\n",
    "    text=text.lower()\n",
    "    new_text=text\n",
    "    text=text.split()\n",
    "    for word in text:\n",
    "      if word in self.__reflectionTable:\n",
    "        new_word=self.__reflectionTable[word]\n",
    "        new_text=new_text.replace(word,new_word)\n",
    "\n",
    "    return new_text\n",
    "\n",
    "  def respond(self, text):\n",
    "    \"\"\"\n",
    "      Take a string, find a match, and return a randomly\n",
    "      chosen response from the corresponding list.\n",
    "\n",
    "      Do not forget to \"reflect\" appropriate parts of the string.\n",
    "\n",
    "      If there is no match, return None.\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    #Converting text to lower case\n",
    "    text=text.lower()\n",
    "    for match_pattern, responses in self.__responseTable:\n",
    "      #Regex is case sensitive\n",
    "      match_pattern=match_pattern.lower()\n",
    "      match_found=re.match(match_pattern,text)\n",
    "      if match_found:\n",
    "        #Finding the sentence using the capture group\n",
    "        captured_sentence=match_found.group(1)\n",
    "        #reflecting the sentence\n",
    "        reflected_sentence=self.reflect(captured_sentence)\n",
    "        #Picking up a random response from the responses and then reflecting it\n",
    "        random_response=random.choice(responses)\n",
    "        response=random_response.replace('%1',reflected_sentence)\n",
    "        return response\n",
    "      \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your Bot\n",
    "\n",
    "You can use this interface to manually check your bot's responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def command_interface():\n",
    "    print('Aleeza\\n---------')\n",
    "    print('Talk to the program by typing in plain English.')\n",
    "    print('='*72)\n",
    "    print('Hello.  How are you feeling today?')\n",
    "\n",
    "    s = ''\n",
    "    therapist = Aleeza(reflectionTable, responseTable)\n",
    "    while s != 'quit':\n",
    "        try:\n",
    "            s = input('> ')\n",
    "        except EOFError:\n",
    "            s = 'quit'\n",
    "        print(s)\n",
    "        while s[-1] in '!.':\n",
    "            s = s[:-1]\n",
    "        print(therapist.respond(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleeza\n",
      "---------\n",
      "Talk to the program by typing in plain English.\n",
      "========================================================================\n",
      "Hello.  How are you feeling today?\n",
      "i am sad\n",
      "You are sad?\n",
      "i want to be the best\n",
      "How would that make you feel?\n",
      "i want to play\n",
      "Why do you want to play?\n",
      "i believe i can fly\n",
      "Why do you believe you can fly?\n",
      "hello?\n",
      "Could you please elaborate?\n",
      "hi there\n",
      "I'm sorry. I don't understand\n",
      "he is angry\n",
      "How long has he been angry?\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcommand_interface\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 15\u001b[0m, in \u001b[0;36mcommand_interface\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(s)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!.\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     16\u001b[0m     s \u001b[38;5;241m=\u001b[39m s[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(therapist\u001b[38;5;241m.\u001b[39mrespond(s))\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "command_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Sentences\n",
    "\n",
    "After testing your bot, you have likely seen that it does not work very well yet. This goes to show the immense amount of work that was put into the original ELIZA program.\\\n",
    "In any case, having concocted all of your (hopefully) appropriate responses, you now need to demonstrate your bot handling all the cases listed above. To do this, you must provide an example sentence handling each of the regular expressions you have listed in your response table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cases considered:\n",
    "#1. \"I am (.*)\" -> anything followed by I am ____.\n",
    "#2. I want|feel|think (.*) -> anything followed by I want/feel/think _____.\n",
    "#3. \".*\\?\" -> any thing with a question mark that doesn't have a response\n",
    "#4. \".*\" -> any string, considering cases where we need to respond somethingn and keep convo going.\n",
    "#5. 3 subject verb pairs - I enjoy, I hate, I believe\n",
    "#6 He/she/it only done with is i.e for be verb form\n",
    "test_sentences = [\n",
    "    # Add test sentences here\n",
    "    \"I am sad\",\n",
    "    \"I want to be the best\",\n",
    "    \"I feel that my mom loves me\",\n",
    "    \"Today is a good day\",\n",
    "    \"Can you help me get motivation?\",\n",
    "    \"I think GenAI course is really fascinating\",\n",
    "    \"I believe I can fly\",\n",
    "    \"I hate politics\",\n",
    "    \"I enjoy playing cricket\",\n",
    "    \"He is really angry\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(sentence_list, bot):\n",
    "    \"\"\"\n",
    "    Get a response for each sentence from the list and return as a list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Code here\n",
    "    response_list=[]\n",
    "    for sentence in sentence_list:\n",
    "        response_list.append(bot.respond(sentence))\n",
    "    return response_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "I am sad\n",
      "What makes you sad?\n",
      "========================================================================\n",
      "I want to be the best\n",
      "Why do you want to be the best?\n",
      "========================================================================\n",
      "I feel that my mom loves me\n",
      "Why do you feel that your mom loves you?\n",
      "========================================================================\n",
      "Today is a good day\n",
      "Could you please elaborate?\n",
      "========================================================================\n",
      "Can you help me get motivation?\n",
      "I'm sorry, I don't understand the question.\n",
      "========================================================================\n",
      "I think GenAI course is really fascinating\n",
      "Why do you think genai course are really fascinating?\n",
      "========================================================================\n",
      "I believe I can fly\n",
      "How long have you been believing you can fly?\n",
      "========================================================================\n",
      "I hate politics\n",
      "Why do you hate politics?\n",
      "========================================================================\n",
      "I enjoy playing cricket\n",
      "How do you know that you enjoy playing cricket?\n",
      "========================================================================\n",
      "He is really angry\n",
      "What makes him really angry?\n"
     ]
    }
   ],
   "source": [
    "therapist = Aleeza(reflectionTable, responseTable)\n",
    "\n",
    "for pair in zip(test_sentences, get_responses(test_sentences, therapist)):\n",
    "    print('='*72)\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving Aleeza Emotional Intelligence\n",
    "\n",
    "In the next part of the assignment, you will be giving your chatbot some emotional intelligence. This will be done by training a simple emotion classification model. You will then use this model to classify the sentiment of the user's input and respond accordingly.\\\n",
    "\\\n",
    "How our logic will work is as follows:\n",
    "1. If there is a match in the response table, we will use the response from the table.\n",
    "2. If there is no match, we will classify the emotion of the input and respond accordingly.\n",
    "\n",
    "The model we will use is a simple Naive Bayes Classifier. This is a simple model that works well with text data. You will be using the `scikit-learn` library to train the model, and the huggingface `datasets` library to get the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "These are the ONLY imports you can use for this part of the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.17.0)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (1.26.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets scikit-learn\n",
    "import datasets\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We will be using the `emotion` dataset from the `datasets` library. This dataset contains text data and the corresponding emotion. You will use this data to train your model. Load this dataset using the `load_dataset` function from the `datasets` library.\n",
    "\n",
    "Next, split the dataset into training and testings sets.\\\n",
    "(HINT: This has already been done for you in the dataset you loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the emotion dataset from Hugging Face\n",
    "\"\"\"\n",
    "from datasets import load_dataset\n",
    "dataset =load_dataset('emotion')\n",
    "\n",
    "# print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Split the dataset into training and testing sets\n",
    "\"\"\"\n",
    "# print(dataset['train']['text'])\n",
    "# print(dataset['train']['label'])\n",
    "\n",
    "# Code below\n",
    "train_data = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "test_data = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "Just like in your previous assignment, you will now train the model and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83       581\n",
      "           1       0.74      0.97      0.84       695\n",
      "           2       0.95      0.23      0.37       159\n",
      "           3       0.92      0.57      0.70       275\n",
      "           4       0.82      0.53      0.64       224\n",
      "           5       0.00      0.00      0.00        66\n",
      "\n",
      "    accuracy                           0.77      2000\n",
      "   macro avg       0.69      0.54      0.56      2000\n",
      "weighted avg       0.77      0.77      0.73      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Vectorise the data and train the model\n",
    "\"\"\"\n",
    "\n",
    "#Initialising\n",
    "vectorizer=CountVectorizer()\n",
    "clf=MultinomialNB()\n",
    "\n",
    "#Vectorising the data\n",
    "#The vectoriser is only fit onto the training data and not on the test data so we will fit_transform on training data\n",
    "#but only transform the test datta\n",
    "vectorized_training_data=vectorizer.fit_transform(train_data)\n",
    "vectorized_test_data=vectorizer.transform(test_data)\n",
    "\n",
    "#Training the model\n",
    "clf.fit(vectorized_training_data,train_labels)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Predict on the test set\n",
    "\"\"\"\n",
    "\n",
    "predicted_labels = clf.predict(vectorized_test_data)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Print classification report\n",
    "\"\"\"\n",
    "print(classification_report(test_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "\n",
    "Now that we have our classification model, we can modify our chatbot to use it.\n",
    "\n",
    "First, we will remove the fallback responses from our response table, i.e. the following cases:\n",
    "1. (I feel ...), (I want ...), (I think ...)\n",
    "2. Subject with an unknown verb\n",
    "3. An unrecognised question\n",
    "4. Any string\n",
    "\n",
    "Remove these and save your response table as \"responseTable2.json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new file \"responseTable2.json\" and add your modified table to it\n",
    "\n",
    "responseTable = json.load(open('responseTable2.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Emotion Response Table\n",
    "\n",
    "This table will be a dictionary with the emotions as keys and a list of possible responses as values. You should include at least 2 responses for each emotion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add responses below\n",
    "\n",
    "emotionTable = {\n",
    "    0 : [ # sadness\n",
    "        \"I am sorry to hear that.\",\n",
    "        \"It will be alright. Don't worry!\"\n",
    "    ], \n",
    "    1 : [ # joy\n",
    "        \"I am so happy for you.\",\n",
    "        \"Well, that sounds amazing!!\"\n",
    "    ],\n",
    "    2 : [ # love\n",
    "        \"You seem to have fallen in love with this.\",\n",
    "        \"You really love this!\"\n",
    "    ],\n",
    "    3 : [ # anger\n",
    "        \"It's okay. You need to calm down first.\",\n",
    "        \"Get a glass of water. You seem angry.\"\n",
    "    ],\n",
    "\n",
    "    4 : [ # fear\n",
    "        \"Don't worry. You got this!\",\n",
    "        \"There is nothing to be scared about. Just relax!\"\n",
    "    ],\n",
    "\n",
    "    5 : [ # surprise\n",
    "        \"WOW!\",\n",
    "        \"I AM SURPRISED!\"\n",
    "    ]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying your Chatbot\n",
    "\n",
    "You will now modify your chatbot to use the emotion classifier. If there is a match in the response table, we will use the response from the table. If there is no match, we will classify the emotion of the input and respond accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntelligentAleeza(Aleeza):\n",
    "    def __init__(self, reflectionTable, responseTable, emotionTable, classifier):\n",
    "        \"\"\"\n",
    "        Initialise your bot by calling the parent class's __init__ method,\n",
    "        and then storing the emotionTable as an instance variable.\n",
    "\n",
    "        Next, store the classification model as an instance variable.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Code here\n",
    "        #Calling constructor of parent class\n",
    "        Aleeza.__init__(self,reflectionTable,responseTable)\n",
    "        self.__emotionTable=emotionTable\n",
    "        self.__classifer=classifier\n",
    "\n",
    "    def smart_respond(self, text):\n",
    "        \"\"\"\n",
    "        Take a string, call the parent class's respond method.\n",
    "        If the response is None, then respond based on the emotion.\n",
    "        \"\"\"\n",
    "\n",
    "        # Code here\n",
    "        response_from_parent= self.respond(text)\n",
    "        if response_from_parent!=None:\n",
    "            return response_from_parent\n",
    "        else:\n",
    "            vectorized_sentence=vectorizer.transform([text])\n",
    "            emotion=self.__classifer.predict(vectorized_sentence)\n",
    "            response_acc_to_emotion=random.choice(self.__emotionTable[emotion[0]])\n",
    "            return response_acc_to_emotion\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test your New Bot\n",
    "\n",
    "Randomly select 5 sentences from the test set and test your bot. You should see that it now responds with an appropriate message based on the emotion detected in the input (when there is no match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_responses(sentence_list, bot):\n",
    "    \"\"\"\n",
    "    Get a response for each sentence from the list and return as a list.\n",
    "    Use your new smart_respond method.\n",
    "    \"\"\"\n",
    "    response_list=[]\n",
    "    for sentence in sentence_list:\n",
    "        response_list.append(bot.smart_respond(sentence))\n",
    "    return response_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================\n",
      "i exist for does my existence even mean anything to anyone apart from my family i always wonder about my existence and the fuck now i feel so dumb ive never thought about the purpose of it\n",
      "I am sorry to hear that.\n",
      "========================================================================\n",
      "i feel is he generous\n",
      "I am so happy for you.\n",
      "========================================================================\n",
      "i feel his hand on me to stay faithful\n",
      "Well, that sounds amazing!!\n",
      "========================================================================\n",
      "i feel as though most people will find it quite pleasant\n",
      "Well, that sounds amazing!!\n",
      "========================================================================\n",
      "i still feel more than anything else humiliated whenever i think of everything that s happened\n",
      "I am sorry to hear that.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create an instance of the IntelligentAleeza class\n",
    "\"\"\"\n",
    "intelligent_therapist = IntelligentAleeza(reflectionTable,responseTable,emotionTable,clf)\n",
    "\n",
    "\"\"\"\n",
    "Get 5 random test instances from the test data\n",
    "\"\"\"\n",
    "\n",
    "# Code here\n",
    "test_instances = []\n",
    "for i in range(5):\n",
    "    random_index=random.randint(0, 1999)\n",
    "    test_instances.append(test_data[random_index])\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Get responses from the intelligent_therapist \n",
    "\"\"\"\n",
    "\n",
    "responses = get_responses(test_instances, intelligent_therapist)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Print the test instances and the responses\n",
    "\"\"\"\n",
    "for pair in zip(test_instances, responses):\n",
    "    print('='*72)\n",
    "    print(pair[0])\n",
    "    print(pair[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
